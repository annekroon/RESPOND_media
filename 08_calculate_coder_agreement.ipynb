{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc859c5c-3f8d-4619-b8dc-9f4e5ae07fbf",
   "metadata": {},
   "source": [
    "# Get intercoder agreement stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "32a30cf8-5073-4082-8f85-109f5f9686fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ICR-1 Reliability (human coders only) =====\n",
      "✅ Annotators with ≥15 articles: ['Alexander', 'Assia', 'Elisa', 'Luigia', 'Yara']\n",
      "\n",
      "=== Frame: Foreign influence threat_present (ICR-1) ===\n",
      "  Alexander vs Assia: α = 0.000 (n=15)\n",
      "  Alexander vs Elisa: α = -0.036 (n=15)\n",
      "  Alexander vs Luigia: α = 1.000 (n=15)\n",
      "  Alexander vs Yara: α = 0.000 (n=15)\n",
      "  Assia vs Elisa: α = 0.000 (n=15)\n",
      "  Assia vs Luigia: α = 0.000 (n=15)\n",
      "  Assia vs Yara: α = 1.000 (n=15)\n",
      "  Elisa vs Luigia: α = -0.036 (n=15)\n",
      "  Elisa vs Yara: α = 0.000 (n=15)\n",
      "  Luigia vs Yara: α = 0.000 (n=15)\n",
      "\n",
      "=== Frame: Systemic institutional corruption_present (ICR-1) ===\n",
      "  Alexander vs Assia: α = 0.584 (n=15)\n",
      "  Alexander vs Elisa: α = 0.341 (n=15)\n",
      "  Alexander vs Luigia: α = 0.847 (n=15)\n",
      "  Alexander vs Yara: α = 0.670 (n=15)\n",
      "  Assia vs Elisa: α = 0.233 (n=15)\n",
      "  Assia vs Luigia: α = 0.420 (n=15)\n",
      "  Assia vs Yara: α = 0.540 (n=15)\n",
      "  Elisa vs Luigia: α = 0.460 (n=15)\n",
      "  Elisa vs Yara: α = 0.597 (n=15)\n",
      "  Luigia vs Yara: α = 0.820 (n=15)\n",
      "\n",
      "=== Frame: Elite collusion_present (ICR-1) ===\n",
      "  Alexander vs Assia: α = 0.463 (n=15)\n",
      "  Alexander vs Elisa: α = 0.606 (n=15)\n",
      "  Alexander vs Luigia: α = 0.233 (n=15)\n",
      "  Alexander vs Yara: α = 0.482 (n=15)\n",
      "  Assia vs Elisa: α = 0.306 (n=15)\n",
      "  Assia vs Luigia: α = 0.460 (n=15)\n",
      "  Assia vs Yara: α = 0.194 (n=15)\n",
      "  Elisa vs Luigia: α = 0.341 (n=15)\n",
      "  Elisa vs Yara: α = 0.081 (n=15)\n",
      "  Luigia vs Yara: α = -0.074 (n=15)\n",
      "\n",
      "=== Frame: Politicized investigations_present (ICR-1) ===\n",
      "  Alexander vs Assia: α = 0.670 (n=15)\n",
      "  Alexander vs Elisa: α = 0.820 (n=15)\n",
      "  Alexander vs Luigia: α = 0.442 (n=15)\n",
      "  Alexander vs Yara: α = 1.000 (n=15)\n",
      "  Assia vs Elisa: α = 0.540 (n=15)\n",
      "  Assia vs Luigia: α = 0.194 (n=15)\n",
      "  Assia vs Yara: α = 0.670 (n=15)\n",
      "  Elisa vs Luigia: α = 0.304 (n=15)\n",
      "  Elisa vs Yara: α = 0.820 (n=15)\n",
      "  Luigia vs Yara: α = 0.442 (n=15)\n",
      "\n",
      "=== Frame: Authoritarian reformism_present (ICR-1) ===\n",
      "  Alexander vs Assia: α = -0.036 (n=15)\n",
      "  Alexander vs Elisa: α = -0.036 (n=15)\n",
      "  Alexander vs Luigia: α = -0.074 (n=15)\n",
      "  Alexander vs Yara: α = -0.036 (n=15)\n",
      "  Assia vs Elisa: α = -0.115 (n=15)\n",
      "  Assia vs Luigia: α = 0.304 (n=15)\n",
      "  Assia vs Yara: α = 0.442 (n=15)\n",
      "  Elisa vs Luigia: α = 0.768 (n=15)\n",
      "  Elisa vs Yara: α = 0.442 (n=15)\n",
      "  Luigia vs Yara: α = 0.768 (n=15)\n",
      "\n",
      "=== Frame: Judicial and institutional accountability failures_present (ICR-1) ===\n",
      "  Alexander vs Assia: α = 0.233 (n=15)\n",
      "  Alexander vs Elisa: α = 0.861 (n=15)\n",
      "  Alexander vs Luigia: α = 0.344 (n=15)\n",
      "  Alexander vs Yara: α = 0.223 (n=15)\n",
      "  Assia vs Elisa: α = 0.130 (n=15)\n",
      "  Assia vs Luigia: α = 0.194 (n=15)\n",
      "  Assia vs Yara: α = 0.344 (n=15)\n",
      "  Elisa vs Luigia: α = 0.223 (n=15)\n",
      "  Elisa vs Yara: α = 0.356 (n=15)\n",
      "  Luigia vs Yara: α = 0.344 (n=15)\n",
      "\n",
      "=== Frame: Mobilizing anti-corruption_present (ICR-1) ===\n",
      "  Alexander vs Assia: α = 0.597 (n=15)\n",
      "  Alexander vs Elisa: α = 0.460 (n=15)\n",
      "  Alexander vs Luigia: α = 0.460 (n=15)\n",
      "  Alexander vs Yara: α = 0.768 (n=15)\n",
      "  Assia vs Elisa: α = 0.847 (n=15)\n",
      "  Assia vs Luigia: α = 0.847 (n=15)\n",
      "  Assia vs Yara: α = 0.820 (n=15)\n",
      "  Elisa vs Luigia: α = 0.710 (n=15)\n",
      "  Elisa vs Yara: α = 0.670 (n=15)\n",
      "  Luigia vs Yara: α = 0.670 (n=15)\n",
      "\n",
      "✅ ICR-1 results saved to /home/akroon/webdav/ASCOR-FMG-5580-RESPOND-news-data (Projectfolder)/annotations/coding_frames/ICR/ICR_test1/reliability_results_icr1_human_only.xlsx\n",
      "\n",
      "===== ICR-2 Reliability (human coders only) =====\n",
      "✅ Annotators with ≥15 articles: ['Alexander', 'Assia', 'Elisa', 'Luigia', 'Yara']\n",
      "\n",
      "=== Frame: Foreign influence threat_present (ICR-2) ===\n",
      "  Alexander vs Assia: α = 0.642 (n=15)\n",
      "  Alexander vs Elisa: α = 1.000 (n=15)\n",
      "  Alexander vs Luigia: α = 1.000 (n=15)\n",
      "  Alexander vs Yara: α = 1.000 (n=15)\n",
      "  Assia vs Elisa: α = 0.642 (n=15)\n",
      "  Assia vs Luigia: α = 0.642 (n=15)\n",
      "  Assia vs Yara: α = 0.642 (n=15)\n",
      "  Elisa vs Luigia: α = 1.000 (n=15)\n",
      "  Elisa vs Yara: α = 1.000 (n=15)\n",
      "  Luigia vs Yara: α = 1.000 (n=15)\n",
      "\n",
      "=== Frame: Systemic institutional corruption_present (ICR-2) ===\n",
      "  Alexander vs Assia: α = 0.670 (n=15)\n",
      "  Alexander vs Elisa: α = 0.597 (n=15)\n",
      "  Alexander vs Luigia: α = 0.194 (n=15)\n",
      "  Alexander vs Yara: α = 0.597 (n=15)\n",
      "  Assia vs Elisa: α = 0.597 (n=15)\n",
      "  Assia vs Luigia: α = 0.194 (n=15)\n",
      "  Assia vs Yara: α = 0.597 (n=15)\n",
      "  Elisa vs Luigia: α = 0.442 (n=15)\n",
      "  Elisa vs Yara: α = 0.442 (n=15)\n",
      "  Luigia vs Yara: α = 0.442 (n=15)\n",
      "\n",
      "=== Frame: Elite collusion_present (ICR-2) ===\n",
      "  Alexander vs Assia: α = 0.861 (n=15)\n",
      "  Alexander vs Elisa: α = 0.584 (n=15)\n",
      "  Alexander vs Luigia: α = 0.731 (n=15)\n",
      "  Alexander vs Yara: α = 1.000 (n=15)\n",
      "  Assia vs Elisa: α = 0.463 (n=15)\n",
      "  Assia vs Luigia: α = 0.606 (n=15)\n",
      "  Assia vs Yara: α = 0.861 (n=15)\n",
      "  Elisa vs Luigia: α = 0.869 (n=15)\n",
      "  Elisa vs Yara: α = 0.584 (n=15)\n",
      "  Luigia vs Yara: α = 0.731 (n=15)\n",
      "\n",
      "=== Frame: Politicized investigations_present (ICR-2) ===\n",
      "  Alexander vs Assia: α = 0.099 (n=15)\n",
      "  Alexander vs Elisa: α = 1.000 (n=15)\n",
      "  Alexander vs Luigia: α = 1.000 (n=15)\n",
      "  Alexander vs Yara: α = 1.000 (n=15)\n",
      "  Assia vs Elisa: α = 0.099 (n=15)\n",
      "  Assia vs Luigia: α = 0.099 (n=15)\n",
      "  Assia vs Yara: α = 0.099 (n=15)\n",
      "  Elisa vs Luigia: α = 1.000 (n=15)\n",
      "  Elisa vs Yara: α = 1.000 (n=15)\n",
      "  Luigia vs Yara: α = 1.000 (n=15)\n",
      "\n",
      "=== Frame: Authoritarian reformism_present (ICR-2) ===\n",
      "  Alexander vs Assia: α = 0.642 (n=15)\n",
      "  Alexander vs Elisa: α = 0.642 (n=15)\n",
      "  Alexander vs Luigia: α = 1.000 (n=15)\n",
      "  Alexander vs Yara: α = 1.000 (n=15)\n",
      "  Assia vs Elisa: α = 0.442 (n=15)\n",
      "  Assia vs Luigia: α = 0.642 (n=15)\n",
      "  Assia vs Yara: α = 0.642 (n=15)\n",
      "  Elisa vs Luigia: α = 0.642 (n=15)\n",
      "  Elisa vs Yara: α = 0.642 (n=15)\n",
      "  Luigia vs Yara: α = 1.000 (n=15)\n",
      "\n",
      "=== Frame: Judicial and institutional accountability failures_present (ICR-2) ===\n",
      "  Alexander vs Assia: α = 0.584 (n=15)\n",
      "  Alexander vs Elisa: α = 0.540 (n=15)\n",
      "  Alexander vs Luigia: α = 0.597 (n=15)\n",
      "  Alexander vs Yara: α = 0.820 (n=15)\n",
      "  Assia vs Elisa: α = 0.463 (n=15)\n",
      "  Assia vs Luigia: α = 0.233 (n=15)\n",
      "  Assia vs Yara: α = 0.420 (n=15)\n",
      "  Elisa vs Luigia: α = 0.460 (n=15)\n",
      "  Elisa vs Yara: α = 0.670 (n=15)\n",
      "  Luigia vs Yara: α = 0.768 (n=15)\n",
      "\n",
      "=== Frame: Mobilizing anti-corruption_present (ICR-2) ===\n",
      "  Alexander vs Assia: α = -0.115 (n=15)\n",
      "  Alexander vs Elisa: α = -0.115 (n=15)\n",
      "  Alexander vs Luigia: α = 0.442 (n=15)\n",
      "  Alexander vs Yara: α = 0.442 (n=15)\n",
      "  Assia vs Elisa: α = -0.036 (n=15)\n",
      "  Assia vs Luigia: α = -0.036 (n=15)\n",
      "  Assia vs Yara: α = -0.036 (n=15)\n",
      "  Elisa vs Luigia: α = -0.036 (n=15)\n",
      "  Elisa vs Yara: α = -0.036 (n=15)\n",
      "  Luigia vs Yara: α = 1.000 (n=15)\n",
      "\n",
      "✅ ICR-2 results saved to /home/akroon/webdav/ASCOR-FMG-5580-RESPOND-news-data (Projectfolder)/annotations/coding_frames/ICR/ICR_test2/reliability_results_icr2_human_only.xlsx\n",
      "\n",
      "===== Final Intercoder Reliability Summary =====\n",
      "\n",
      "✅ Final summary saved to /home/akroon/webdav/ASCOR-FMG-5580-RESPOND-news-data (Projectfolder)/annotations/coding_frames/ICR/final_intercoder_reliability_summary.xlsx\n",
      "\n",
      "=== Final Summary ===\n",
      "                             frame  % agreement  cohen_kappa  n_items  \\\n",
      "0  Authoritarian reformism_present      96.6650      0.81700       15   \n",
      "1          Elite collusion_present      90.0000      0.78875       15   \n",
      "2  Foreign influence threat_presen      98.3325      0.90850       15   \n",
      "3  Judicial and institutional acco      86.6650      0.67200       15   \n",
      "4  Mobilizing anti-corruption_pres      90.0000      0.72775       30   \n",
      "5  Politicized investigations_pres      91.6675      0.73150       30   \n",
      "6  Systemic institutional corrupti      86.6675      0.65250       30   \n",
      "\n",
      "  annotator  krippendorff_alpha  \n",
      "0   Average               0.632  \n",
      "1   Average               0.678  \n",
      "2   Average               0.783  \n",
      "3   Average               0.474  \n",
      "4   Average               0.482  \n",
      "5   Average               0.445  \n",
      "6   Average               0.468  \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import krippendorff\n",
    "from itertools import combinations\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# === COMMON SETTINGS ===\n",
    "FRAME_LABELS = [\n",
    "    \"Foreign influence threat_present\",\n",
    "    \"Systemic institutional corruption_present\",\n",
    "    \"Elite collusion_present\",\n",
    "    \"Politicized investigations_present\",\n",
    "    \"Authoritarian reformism_present\",\n",
    "    \"Judicial and institutional accountability failures_present\",\n",
    "    \"Mobilizing anti-corruption_present\"\n",
    "]\n",
    "\n",
    "def encode_label(val):\n",
    "    \"\"\"Encode 'Present' as 1, 'Not Present' as 0, else None.\"\"\"\n",
    "    return 1 if val == \"Present\" else 0 if val == \"Not Present\" else None\n",
    "\n",
    "def load_all_annotations(session_folder, allowed_annotators, min_articles=15):\n",
    "    \"\"\"\n",
    "    Load all session JSON files and return a DataFrame of annotations.\n",
    "    Only annotators with at least `min_articles` unique URIs are retained.\n",
    "    \"\"\"\n",
    "    data = []\n",
    "    for filename in os.listdir(session_folder):\n",
    "        if filename.endswith(\"_session.json\"):\n",
    "            user_id = filename.replace(\"_session.json\", \"\")\n",
    "            path = os.path.join(session_folder, filename)\n",
    "            with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "                session_data = json.load(f)\n",
    "                for ann in session_data.get(\"annotations\", []):\n",
    "                    ann[\"user_id\"] = user_id\n",
    "                    data.append(ann)\n",
    "    df = pd.DataFrame(data)\n",
    "    df = df[df[\"user_id\"].isin(allowed_annotators)]\n",
    "    annotator_counts = df.groupby(\"user_id\")[\"uri\"].nunique()\n",
    "    complete_annotators = annotator_counts[annotator_counts >= min_articles].index.tolist()\n",
    "    df = df[df[\"user_id\"].isin(complete_annotators)]\n",
    "    print(f\"✅ Annotators with ≥{min_articles} articles: {complete_annotators}\")\n",
    "    return df\n",
    "\n",
    "def prepare_matrix(df, frame_label):\n",
    "    \"\"\"Pivot the annotation DataFrame into a coder×URI matrix of binary labels.\"\"\"\n",
    "    df_sub = df[[\"user_id\", \"uri\", frame_label]].copy()\n",
    "    df_sub[frame_label] = df_sub[frame_label].map(encode_label)\n",
    "    return df_sub.pivot(index=\"uri\", columns=\"user_id\", values=frame_label)\n",
    "\n",
    "def safe_krippendorff_alpha(data, level='nominal'):\n",
    "    \"\"\"Compute Krippendorff’s α, returning 1.0 or NaN when appropriate.\"\"\"\n",
    "    unique_vals = np.unique(data[~np.isnan(data)])\n",
    "    if len(unique_vals) < 2:\n",
    "        return 1.0\n",
    "    try:\n",
    "        alpha = krippendorff.alpha(reliability_data=data, level_of_measurement=level)\n",
    "        return alpha if not isinstance(alpha, (np.ndarray, list)) else np.nan\n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error computing alpha: {e}\")\n",
    "        return np.nan\n",
    "\n",
    "def pairwise_krippendorff(matrix, coders):\n",
    "    \"\"\"Compute pairwise Krippendorff’s α for all coder pairs.\"\"\"\n",
    "    results = {}\n",
    "    for coder1, coder2 in combinations(coders, 2):\n",
    "        pair_data = matrix[[coder1, coder2]].dropna()\n",
    "        n_rows = pair_data.shape[0]\n",
    "        alpha = safe_krippendorff_alpha(pair_data.to_numpy().T) if n_rows > 0 else np.nan\n",
    "        results[(coder1, coder2)] = (alpha, n_rows)\n",
    "    return results\n",
    "\n",
    "def compute_human_reliability(\n",
    "    session_folder,\n",
    "    output_excel,\n",
    "    allowed_annotators=None,\n",
    "    min_articles=15,\n",
    "    label=\"ICR\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute per-frame reliability for a given session folder (human coders only).\n",
    "    Writes results to `output_excel` and returns a DataFrame.\n",
    "    \"\"\"\n",
    "    if allowed_annotators is None:\n",
    "        allowed_annotators = [\"Assia\", \"Alexander\", \"Elisa\", \"Luigia\", \"Yara\"]\n",
    "    df = load_all_annotations(session_folder, allowed_annotators, min_articles=min_articles)\n",
    "    results = []\n",
    "    for frame_label in FRAME_LABELS:\n",
    "        print(f\"\\n=== Frame: {frame_label} ({label}) ===\")\n",
    "        matrix = prepare_matrix(df, frame_label)\n",
    "        coders_with_data = [c for c in matrix.columns if matrix[c].notna().any()]\n",
    "        pairwise_alphas = pairwise_krippendorff(matrix, coders_with_data)\n",
    "        for (c1, c2), (alpha, n_rows) in sorted(pairwise_alphas.items()):\n",
    "            print(f\"  {c1} vs {c2}: α = {alpha:.3f} (n={n_rows})\" if not np.isnan(alpha)\n",
    "                  else f\"  {c1} vs {c2}: α = N/A (n={n_rows})\")\n",
    "        complete_data = matrix.dropna(how='any')\n",
    "        overall_alpha = safe_krippendorff_alpha(complete_data.to_numpy().T) if not complete_data.empty else np.nan\n",
    "        disagreement_count = complete_data.apply(lambda row: len(set(row)), axis=1)\n",
    "        num_disagreements = (disagreement_count > 1).sum()\n",
    "        num_agreements = (disagreement_count == 1).sum()\n",
    "        num_articles_coded_by_all = complete_data.shape[0]\n",
    "        results.append({\n",
    "            \"frame\": frame_label,\n",
    "            \"overall_alpha\": overall_alpha,\n",
    "            \"avg_pairwise_alpha\": np.mean([v[0] for v in pairwise_alphas.values() if not np.isnan(v[0])]),\n",
    "            \"num_disagreements\": num_disagreements,\n",
    "            \"num_agreements\": num_agreements,\n",
    "            \"num_articles_coded_by_all\": num_articles_coded_by_all\n",
    "        })\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df.to_excel(output_excel, index=False)\n",
    "    print(f\"\\n✅ {label} results saved to {output_excel}\")\n",
    "    return results_df\n",
    "\n",
    "# === LOW-LEVEL α FOR FINAL SUMMARY ===\n",
    "def krippendorff_alpha_nominal(data):\n",
    "    values = pd.unique(data[~pd.isnull(data)])\n",
    "    if len(values) <= 1:\n",
    "        return 1.0\n",
    "    cm = pd.DataFrame(0, index=values, columns=values, dtype=int)\n",
    "    for row in data.T:\n",
    "        row = row[~pd.isnull(row)]\n",
    "        for i, j in combinations(row, 2):\n",
    "            cm.loc[i, j] += 1\n",
    "            cm.loc[j, i] += 1\n",
    "    total = cm.to_numpy().sum()\n",
    "    if total == 0:\n",
    "        return np.nan\n",
    "    Do = sum(cm.loc[i, j] * (0 if i == j else 1) for i in values for j in values)\n",
    "    marginals = cm.sum(axis=0)\n",
    "    De = sum(\n",
    "        marginals[i] * marginals[j] * (0 if i == j else 1)\n",
    "        for i in range(len(values)) for j in range(len(values))\n",
    "    ) / (total - 1)\n",
    "    if De == 0:\n",
    "        return 1.0\n",
    "    return round(1 - Do / De, 3)\n",
    "\n",
    "def main_intercoder_reliability(\n",
    "    main_file,\n",
    "    extra_file=None,\n",
    "    extra_frames=None,\n",
    "    output_file=\"final_intercoder_reliability_summary.xlsx\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute average κ vs Yara and Krippendorff’s α per frame.\n",
    "    Extra frames override the main file where provided.\n",
    "    Returns the summary and detailed coder-vs-Yara dataframe.\n",
    "    \"\"\"\n",
    "    if extra_frames is None:\n",
    "        extra_frames = []\n",
    "    exclude_cols = [\"URI\", \"Translated Text\", \"Yara\", \"Yara.1\", \"LLM\", \"LLM_Updated\"]\n",
    "\n",
    "    main_xls = pd.ExcelFile(main_file)\n",
    "    extra_xls = pd.ExcelFile(extra_file) if extra_file else None\n",
    "\n",
    "    def process_sheet(df, frame):\n",
    "        df.columns = df.columns.str.strip()\n",
    "        if \"Yara\" not in df.columns:\n",
    "            return pd.DataFrame()\n",
    "        coders = [c for c in df.columns if c not in exclude_cols]\n",
    "        records = []\n",
    "        for coder in coders:\n",
    "            valid = df[[coder, \"Yara\"]].dropna()\n",
    "            if valid.empty:\n",
    "                continue\n",
    "            kappa = cohen_kappa_score(valid[coder], valid[\"Yara\"])\n",
    "            agree = (valid[coder] == valid[\"Yara\"]).mean()\n",
    "            records.append({\n",
    "                \"frame\": frame,\n",
    "                \"annotator\": coder,\n",
    "                \"% agreement\": round(agree * 100, 2),\n",
    "                \"cohen_kappa\": round(kappa, 3),\n",
    "                \"n_items\": valid.shape[0]\n",
    "            })\n",
    "        return pd.DataFrame(records)\n",
    "\n",
    "    # Build coder-vs-Yara data\n",
    "    main_dfs = []\n",
    "    for sheet in main_xls.sheet_names:\n",
    "        df = pd.read_excel(main_xls, sheet_name=sheet)\n",
    "        main_dfs.append(process_sheet(df, sheet))\n",
    "    main_df = pd.concat(main_dfs, ignore_index=True)\n",
    "\n",
    "    extra_df = pd.DataFrame()\n",
    "    if extra_xls:\n",
    "        extra_dfs = []\n",
    "        for sheet in extra_xls.sheet_names:\n",
    "            if sheet in extra_frames:\n",
    "                df = pd.read_excel(extra_xls, sheet_name=sheet)\n",
    "                extra_dfs.append(process_sheet(df, sheet))\n",
    "        extra_df = pd.concat(extra_dfs, ignore_index=True)\n",
    "\n",
    "    # Combine, giving priority to extra frames\n",
    "    combined_df = pd.concat(\n",
    "        [main_df[~main_df[\"frame\"].isin(extra_frames)], extra_df],\n",
    "        ignore_index=True\n",
    "    )\n",
    "\n",
    "    # Count unique URIs per frame\n",
    "    uri_counts = {}\n",
    "    for sheet in main_xls.sheet_names:\n",
    "        if sheet not in extra_frames:\n",
    "            df = pd.read_excel(main_xls, sheet_name=sheet)\n",
    "            df.columns = df.columns.str.strip()\n",
    "            uri_counts[sheet] = df[\"URI\"].nunique()\n",
    "    if extra_xls:\n",
    "        for sheet in extra_frames:\n",
    "            df1 = pd.read_excel(extra_xls, sheet_name=sheet)\n",
    "            df2 = pd.read_excel(main_xls, sheet_name=sheet)\n",
    "            combined = pd.concat([df1[\"URI\"], df2[\"URI\"]])\n",
    "            uri_counts[sheet] = combined.nunique()\n",
    "\n",
    "    # Attach correct n_items\n",
    "    combined_df[\"n_items\"] = combined_df[\"frame\"].map(uri_counts)\n",
    "\n",
    "    # Aggregate % agreement and κ per frame\n",
    "    summary = (\n",
    "        combined_df.groupby(\"frame\")\n",
    "        .agg({\n",
    "            \"% agreement\": \"mean\",\n",
    "            \"cohen_kappa\": \"mean\",\n",
    "            \"n_items\": \"first\"\n",
    "        })\n",
    "        .reset_index()\n",
    "    )\n",
    "    summary[\"annotator\"] = \"Average\"\n",
    "\n",
    "    # Compute Krippendorff’s α per frame (merge main and extra if needed)\n",
    "    kripp_dict = {}\n",
    "    for sheet in main_xls.sheet_names:\n",
    "        df = pd.read_excel(main_xls, sheet_name=sheet)\n",
    "        df.columns = df.columns.str.strip()\n",
    "        if sheet in extra_frames and extra_xls:\n",
    "            df2 = pd.read_excel(extra_xls, sheet_name=sheet)\n",
    "            df = pd.concat([df, df2], ignore_index=True)\n",
    "            df.columns = df.columns.str.strip()\n",
    "        coders = [c for c in df.columns if c not in exclude_cols]\n",
    "        matrix = df[coders].T.to_numpy()\n",
    "        kripp_dict[sheet] = krippendorff_alpha_nominal(matrix)\n",
    "\n",
    "    kripp_df = pd.DataFrame(\n",
    "        [(frame, alpha) for frame, alpha in kripp_dict.items()],\n",
    "        columns=[\"frame\", \"krippendorff_alpha\"]\n",
    "    )\n",
    "    summary = summary.merge(kripp_df, on=\"frame\", how=\"left\")\n",
    "\n",
    "    # Export to Excel\n",
    "    with pd.ExcelWriter(output_file) as writer:\n",
    "        summary.to_excel(writer, sheet_name=\"summary\", index=False)\n",
    "        combined_df.to_excel(writer, sheet_name=\"coder_vs_yara\", index=False)\n",
    "\n",
    "    print(f\"\\n✅ Final summary saved to {output_file}\")\n",
    "    return summary, combined_df\n",
    "\n",
    "def plot_results(results_df, title):\n",
    "    sns.set(style=\"whitegrid\")\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    results_df_sorted = results_df.sort_values(\"overall_alpha\", ascending=False)\n",
    "    ax = sns.barplot(data=results_df_sorted, x=\"overall_alpha\", y=\"frame\", palette=\"viridis\")\n",
    "    ax.set_title(title, fontsize=16)\n",
    "    ax.set_xlabel(\"Overall α\", fontsize=12)\n",
    "    ax.set_ylabel(\"Frame\", fontsize=12)\n",
    "    ax.set_xlim(0, 1)\n",
    "    for i, val in enumerate(results_df_sorted[\"overall_alpha\"]):\n",
    "        if not np.isnan(val):\n",
    "            ax.text(val + 0.02, i, f\"{val:.2f}\", va='center')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# === DRIVER ===\n",
    "if __name__ == \"__main__\":\n",
    "    # ICR-1 session folder (human-only)\n",
    "    icr1_session_folder = os.path.expanduser(\n",
    "        \"~/webdav/ASCOR-FMG-5580-RESPOND-news-data (Projectfolder)/sessions/\"\n",
    "    )\n",
    "    icr1_output = os.path.expanduser(\n",
    "        \"~/webdav/ASCOR-FMG-5580-RESPOND-news-data (Projectfolder)/annotations/\"\n",
    "        \"coding_frames/ICR/ICR_test1/reliability_results_icr1_human_only.xlsx\"\n",
    "    )\n",
    "\n",
    "    # ICR-2 session folder (human-only)\n",
    "    icr2_session_folder = (\n",
    "        \"/home/akroon/webdav/ASCOR-FMG-5580-RESPOND-news-data (Projectfolder)/\"\n",
    "        \"annotations/coding_frames/ICR/ICR_test2/sessions\"\n",
    "    )\n",
    "    icr2_output = os.path.expanduser(\n",
    "        \"~/webdav/ASCOR-FMG-5580-RESPOND-news-data (Projectfolder)/annotations/\"\n",
    "        \"coding_frames/ICR/ICR_test2/reliability_results_icr2_human_only.xlsx\"\n",
    "    )\n",
    "\n",
    "    # Final summary file paths\n",
    "    main_file = (\n",
    "        \"/home/akroon/webdav/ASCOR-FMG-5580-RESPOND-news-data (Projectfolder)/annotations/\"\n",
    "        \"coding_frames/ICR/ICR_test2/agreement_with_yara_and_text_icr2.xlsx\"\n",
    "    )\n",
    "    extra_file = (\n",
    "        \"/home/akroon/webdav/ASCOR-FMG-5580-RESPOND-news-data (Projectfolder)/annotations/\"\n",
    "        \"coding_frames/ICR/ICR_test1/agreement_with_yara_and_text.xlsx\"\n",
    "    )\n",
    "    extra_frames = [\n",
    "        \"Mobilizing anti-corruption_pres\",\n",
    "        \"Systemic institutional corrupti\",\n",
    "        \"Politicized investigations_pres\"\n",
    "    ]\n",
    "    final_output = (\n",
    "        \"/home/akroon/webdav/ASCOR-FMG-5580-RESPOND-news-data (Projectfolder)/annotations/\"\n",
    "        \"coding_frames/ICR/final_intercoder_reliability_summary.xlsx\"\n",
    "    )\n",
    "\n",
    "    # 1. Compute ICR-1 reliability (human coders only) and save to ICR_test1 folder\n",
    "    print(\"===== ICR-1 Reliability (human coders only) =====\")\n",
    "    icr1_results = compute_human_reliability(\n",
    "        session_folder=icr1_session_folder,\n",
    "        output_excel=icr1_output,\n",
    "        label=\"ICR-1\"\n",
    "    )\n",
    "\n",
    "    # 2. Compute ICR-2 reliability (human coders only) and save to ICR_test2 folder\n",
    "    print(\"\\n===== ICR-2 Reliability (human coders only) =====\")\n",
    "    icr2_results = compute_human_reliability(\n",
    "        session_folder=icr2_session_folder,\n",
    "        output_excel=icr2_output,\n",
    "        label=\"ICR-2\"\n",
    "    )\n",
    "\n",
    "    # Optionally plot the results for each round\n",
    "    #plot_results(icr1_results, \"ICR-1: Overall Krippendorff's Alpha per Frame (human coders only)\")\n",
    "    #plot_results(icr2_results, \"ICR-2: Overall Krippendorff's Alpha per Frame (human coders only)\")\n",
    "\n",
    "    # 3. Compute the final combined summary (κ vs Yara and α)\n",
    "    print(\"\\n===== Final Intercoder Reliability Summary =====\")\n",
    "    summary_df, coder_vs_yara_df = main_intercoder_reliability(\n",
    "        main_file=main_file,\n",
    "        extra_file=extra_file,\n",
    "        extra_frames=extra_frames,\n",
    "        output_file=final_output\n",
    "    )\n",
    "\n",
    "    # Inspect the final summary\n",
    "    print(\"\\n=== Final Summary ===\")\n",
    "    print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a3aab5-3757-414e-a664-9658c7f64985",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
